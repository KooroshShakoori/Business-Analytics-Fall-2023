{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847e8dd4-93a2-4ca5-b89e-6edb9836b9ed",
   "metadata": {},
   "source": [
    "# Business Analytics - Assignment 3\n",
    "#### **Student Name:** Koorosh Shakoori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca4022a-d46b-48bc-9442-8c37988de465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c114ce-70e9-471d-bb8d-3c0a3005a709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reading the data and making individual predictor and predictand Series of X and y.\n",
    "data = pd.read_csv('MiniExam3DataSet.csv')\n",
    "data.head()\n",
    "X = data.x.values.reshape(-1,1)\n",
    "y = data.y.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c302d1-4943-44b5-8402-4605d9f8eee1",
   "metadata": {},
   "source": [
    "## (a)\n",
    "In this part of the assignment it is requested to split the given dataset into train and test datasets with 0.2 test ratio.\n",
    "\n",
    "We use train_test_split module from scikit-learn for this task.\n",
    "\n",
    "To avoid incosistency we assign a constant random_state value in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6178ea3c-b177-43eb-8196-fc8a2e107a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec08c7c-8347-4826-9ff5-436820bb35c8",
   "metadata": {},
   "source": [
    "## (b)\n",
    "In this section it is requested to try and compare various polynomial degrees using Mean Squared Error of LOOCV.\n",
    "\n",
    "Then we proceed with picking the degree that resulted in least error in the validation process.\n",
    "\n",
    "For this purpose, we investigate degrees 1 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a24fe97-3bb3-4ada-95f4-a220a80c32e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b574d1b0-0f5a-4f17-a83d-72bcf49b1dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a polynomial function with 3 degrees results in minimum LOO cross validation MSE\n",
      "   degree         MSE\n",
      "0       1  519.422915\n",
      "1       2  624.974783\n",
      "2       3   10.768963\n",
      "3       4   14.050213\n",
      "4       5   20.232977\n",
      "5       6   17.073647\n",
      "6       7   26.696216\n",
      "7       8  102.643631\n",
      "8       9   56.064143\n"
     ]
    }
   ],
   "source": [
    "loocv_scores = []\n",
    "for i in range(1, 10):\n",
    "    #The training data is transformed into polynomial feature so we can later run them through the models.\n",
    "    polynomial_feature = PolynomialFeatures(degree=i, include_bias=False)\n",
    "    X_poly_train = polynomial_feature.fit_transform(X_train)\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    #Since the scoring methods in cross_val_score is implemented in a way to be handled the same way as accuracy(higher is better),\n",
    "    #the MSE provided is negative. Hence, we will use the in-built abs() function to get the positive results.\n",
    "    #Also every score is for one test, therefore we use the mean to see the overall performance of each degree.\n",
    "    loo_score = abs(cross_val_score(model, X_poly_train, y_train, cv=LeaveOneOut(), scoring='neg_mean_squared_error').mean())\n",
    "    loocv_scores.append((i, loo_score))\n",
    "\n",
    "scores = pd.DataFrame(loocv_scores, columns = ['degree', 'MSE'])\n",
    "loo_ideal_degree = scores.degree[scores.MSE.idxmin()]\n",
    "print(f'a polynomial function with {loo_ideal_degree} degrees results in minimum LOO cross validation MSE')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575ea70-5afd-4338-974d-d494ef54b265",
   "metadata": {},
   "source": [
    "## (c)\n",
    "The results above show that Leave One Out cross validation method suggests the superiority of a degree 3 polynomial function.\n",
    "\n",
    "This value is stored in loo_ideal_degree and is used below.\n",
    "\n",
    "Therefore, as requested in problem we refit the model with the suggested degree on full train dataset, and get the test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ee9cd7-3844-4627-829b-b42a21bf361d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error over the test dataset is :7.38539544607036\n"
     ]
    }
   ],
   "source": [
    "#transforming both train and test data into polynomial features with the ideal degree yielded above.\n",
    "polynomial_feature = PolynomialFeatures(degree=loo_ideal_degree, include_bias=False)\n",
    "X_poly_train = polynomial_feature.fit_transform(X_train)\n",
    "X_poly_test = polynomial_feature.fit_transform(X_test)\n",
    "\n",
    "#Initializing and training the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "#Making predictions with test dataset to determine its respective MSE\n",
    "test_prediction = model.predict(X_poly_test)\n",
    "test_MSE = mean_squared_error(y_test, test_prediction)\n",
    "print(f'The Mean Squared Error over the test dataset is :{test_MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78822e-b4fb-49ed-9eff-12747f803250",
   "metadata": {},
   "source": [
    "## (d)\n",
    "In this block, the same approach is followed as part b, however this time for 5-fold cross validation.\n",
    "\n",
    "Again, the degree between 1 and 9 with minimum cross validation MSE is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3995548a-8118-42bb-8732-51e73649b1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a polynomial function with 3 degrees results in minimum 5-fold cross validation MSE\n",
      "   degree         MSE\n",
      "0       1  493.015798\n",
      "1       2  599.487773\n",
      "2       3   11.669149\n",
      "3       4   13.458086\n",
      "4       5   17.678115\n",
      "5       6   13.379101\n",
      "6       7   26.355376\n",
      "7       8  426.319639\n",
      "8       9   40.997351\n"
     ]
    }
   ],
   "source": [
    "kfold_scores = []\n",
    "for i in range(1, 10):\n",
    "    polynomial_feature = PolynomialFeatures(degree=i, include_bias=False)\n",
    "    X_poly_train = polynomial_feature.fit_transform(X_train)\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    #Same as above, the MSE provided by the scroing is negative, hence the abs() function\n",
    "    #This time .mean() function gives the mean of all errors over the 5 iterations.\n",
    "    kfold_score = abs(cross_val_score(model, X_poly_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "    kfold_scores.append((i, kfold_score))\n",
    "\n",
    "scores = pd.DataFrame(kfold_scores, columns = ['degree', 'MSE'])\n",
    "kfold_ideal_degree = scores.degree[scores.MSE.idxmin()]\n",
    "print(f'a polynomial function with {kfold_ideal_degree} degrees results in minimum 5-fold cross validation MSE')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1362996-f2fa-4f0a-8948-f4cbd63bd62a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (e)\n",
    "Once again with the optimal polynomial degree at hand(stored in kfold_ideal_degree), we refit the model with training dataset.\n",
    "\n",
    "This time in addition to MSE for the test dataset we also compute the R2 score according to the needs of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6097a6a-922b-4f06-9ae1-a2b8ed9e7d46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error over the test dataset is :7.38539544607036\n",
      "The R2 score over the test dataset is :0.9819137069010943\n"
     ]
    }
   ],
   "source": [
    "#transforming both train and test data into polynomial features with the ideal degree yielded above.\n",
    "polynomial_feature = PolynomialFeatures(degree=kfold_ideal_degree, include_bias=False)\n",
    "X_poly_train = polynomial_feature.fit_transform(X_train)\n",
    "X_poly_test = polynomial_feature.fit_transform(X_test)\n",
    "\n",
    "#Initializing and training the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly_train, y_train)\n",
    "\n",
    "#Making predictions with test dataset to determine its respective MSE and R2score\n",
    "test_prediction = model.predict(X_poly_test)\n",
    "test_MSE = mean_squared_error(y_test, test_prediction)\n",
    "print(f'The Mean Squared Error over the test dataset is :{test_MSE}')\n",
    "#The R2 score is available as a method of the sklearn model we used in this assignment.\n",
    "R2score = model.score(X_poly_test, y_test)\n",
    "print(f'The R2 score over the test dataset is :{R2score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0585a0c-7dea-411e-b3d5-7ffd864482cb",
   "metadata": {},
   "source": [
    "## (f)\n",
    "Except for some rare random occasions where the distribution of training dataset is highly skewed as a result of splitting the dataset, In most scenarios both cross validation methods suggest the same polynomial degree of **3**. This issue is handled by assigning a random_state argument in the train_test_split function. By assigining this value we can observe that both methods lead into the same number of degrees chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a0dc8b-cb32-43c4-b63a-ffb86610ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a polynomial function with 3 degrees results in minimum LOO cross validation MSE\n",
      "a polynomial function with 3 degrees results in minimum 5-fold cross validation MSE\n"
     ]
    }
   ],
   "source": [
    "print(f'a polynomial function with {loo_ideal_degree} degrees results in minimum LOO cross validation MSE')\n",
    "print(f'a polynomial function with {kfold_ideal_degree} degrees results in minimum 5-fold cross validation MSE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
